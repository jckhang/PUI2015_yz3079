{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maps\n",
    "\n",
    "You have been shown many ways to show maps in python.\n",
    "\n",
    "In the first task where you have to show the location of the top 5 facilities \n",
    "you can use mplleaflet (as was done in the geospatial lecture lab), pylab baseline. You can also use a shapefile to show the zip contours, though the result will be less exciting.\n",
    "In the following portions of the assignment, where you have to show the value of a variable by zipcode (cloropleth), you should use a shapefile and a color map corresponding to the values of the variable, as in HW 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Murder and Green space access metrics__: \n",
    "\n",
    "our recommandation is: \n",
    "\n",
    "\n",
    "find the N nearest locations (N nearest parks, N nearest precints, and N needs not be the same for parks and precints, use your judgment) to the center of each ZIP code; for each park divide the size of the park by the distance to the park, and sum over the parks selected. Similarly, for the murder rate: we found the N nearest precints to the center of the ZIP code, and summed the number of murders for each precint devided by the distance between the precint and the ZIP code center. Further, you may want to try the logarithm of the metrics described above, if you find that they vary too dramatically, to suppress their power. Other solutions can be found. Do whatever you think is most suitable, but describe and motivate what you decided to do, and what your metric of \"access to green spaces\" and \"proximity to violent crimes\" are.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __311 calls__: \n",
    "\n",
    "you can aggregate the 311 calls at the zip code level directly (the zip code is available in the 311 calls data for every call).\n",
    "\n",
    "some of the 311 calls may be directly related to asthma cases: complaints about construction, unsanitary conditions, mold, while others may not (illegally parked cars for example). This is a list of call descriptions which we considered relevant. You can modify this list as you see fit. But you must justify your choice of relevant complaints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validcomplaints = ['UNSANITARY CONDITION','Dirty Conditions', 'Sewer',\n",
    "                   'Hazardous Material','Construction',\n",
    "                   'Indoor Air Quality','Indoor Sewage','Air Quality',\n",
    "                   'HEATING','Industrial Waste','Mold','Asbestos',\n",
    "                   'Sweeping/Missed-Inadequate','Smoking',\n",
    "                   'Non-Residential Heat','Lead','Standing Water',\n",
    "                    'Water Quality','Unsanitary Animal Facility',\n",
    "                   'PAINT - PLASTER','GENERAL CONSTRUCTION']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because complaints to 311 are issued at a different rate in different city areas (due to various reasons including a strong social bias by which wealthier people are generally more engaged and more likely to call) you must normalize the number of relevant calls (calls for one of the reasons in your list) by the total number of calls for that zip code (divide the number of relevant calls by the total number of calls) (normalize = divide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Getting coordinates__:\n",
    "\n",
    "shapefiles read in with geopanda objects as GeoDataFrame contain the attribute geometry:\n",
    "\n",
    "gdf.geometry\n",
    "\n",
    "that contains the attribute centroid\n",
    "\n",
    "gdf.geometry.centroid\n",
    "\n",
    "which (generally) contains an object of type POINT which is a set of 2 numbers: the longitude and latitude in our case. To extract longitude and latitude you can pass the gdf.geometry.centroid object and pass it to a function such as the one below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getXY(pt):\n",
    "    return pt.x, pt.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __ZIPCODE 83__: \n",
    "This may or may not be in your data, as it always happens with NYC data. It may mess things up. http://walk.allcitynewyork.com/2011/07/mysterious-case-of-ghost-zip-code.html\n",
    "        you probably want to remove it (for example to constraint your nyczip files to zips larger than 10000)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __ROCKAWAY 311 calls__ : \n",
    "\n",
    "we found a very large number of relevant calls after normalization in one of the Rockaway ZIP codes. While this may be due to a genuinely high rate of calls about the issues we identified as relevant (water related calls for example) the large number of calls in this ZIP code was skeweing our metric and we artificially suppressed it by replacing it with the mean number of calls. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __using the result of the regression as a metric__\n",
    "\n",
    "Once you have the result of your regression you can use it as a metric for clustering. If you had a linear model for example, then you have something like: \n",
    "\n",
    "$$Asthma\\_Rate = a*(murder\\_rate)+b*(park\\_access)+c*(highway\\_length)+ ...$$\n",
    "\n",
    "Then the coefficients for the $v$ variables: $coef(v)$ ($coef(murder\\_rate) = a$, $coef(park\\_access) = b$, $coef(highway\\_length) = c$) can be used as weights in your distance metric. If you were using a Eucledian distance then the weighted distance $D_{12}$ between ZIP codes $Z_1$ and $Z_2$ would be\n",
    "\n",
    "$$D_{12} = \\sqrt{\\sum_\\mathrm{v\\_in\\_variables} (coef(v)^2*(Z_1(v) - Z_2(v))^2)}$$\n",
    "\n",
    "summed over each $v$ in your model variables (in the case above murder rate, park access, highway length). If your model is more complex (higher degree linear, or non linear) then the distance D would use the variables as they enter in the model (eg the log of the distance if any was included in the regression through its log, a power exponent if you included any of them to any power, maybe a polynomial model for the variable etc etc).\n",
    "\n",
    "Finally notice that since, variable by variable, the corresponding coefficient multiplies each datapoint, in the example above you would not have to define a separate affinity function (like we did in class talking about clustering): you can simply multiply each  data vector $Z(v)$ by the coefficient $coef(v)$ before you feed your data to the clustering algorithm that uses a euclidian distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## converting between coordinate systems\n",
    "some of the files may be in different coordinate systems. \n",
    "to see the coordinate systems of a file you can call the .crs attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nyczips.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in case of naive geometry you may find this useful https://github.com/geopandas/geopandas/issues/245"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to set a GoeDataFrame into the coordinate system of another GeoDataFrame you can do something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkgeo = parksdf.to_crs(nyczips.crs).geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and if you wish you can overwrite the geometry of the original file. This was shown to you in the geospatial lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plotting\n",
    "\n",
    "to plot the contours of a shape file (the zip boundaries) but not the cells in different colors use alpha = 0 as argument. \n",
    "to overplot two GeoDataFrames or a GeoDataFrame and a scatter plot pass an axes argument to the GeoDataFrame plot function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing\n",
    "remember to put your variables in the same order of magnitude before you run regression models, and to whiten the data before clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clustering \n",
    "Use a \"reasonable\" number of clusters. You do not have to be too strict about evaluating the best number, but if you use K-means test for stability, and if you use agglomerative clustering check your dendrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
