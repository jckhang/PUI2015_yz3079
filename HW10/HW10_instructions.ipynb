{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# HW 10 CLUSTERING BUSINESS\n",
    "cluster time trends in NYC businesses: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## DATA: Census Business data:\n",
    "\n",
    "## Download census data for businesses by ZIP code. The data is here http://www.census.gov/econ/cbp/download/\n",
    "\n",
    "## and it can be downloaded by hand. you can also download it with 3 terminal commands as follows: the data from 1993 through 2001 is different in the format of its path than the data after 2001 (that is why more than one for loop is needed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# NYC zip codes shape file is here\n",
    "## http://data.nycprepared.org/dataset/nyc-zip-code-tabulation-areas/resource/0c0e14e9-78e1-404e-97b0-c2fabceb3981\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES: \n",
    "to read in a zip file without unzipping it you can use the pandas and zipfile packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Collecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd data \n",
    "\n",
    "for ((y=93; y<=99; y+=1)); do wget ftp://ftp.census.gov/Econ2001_And_Earlier/CBP_CSV/zbp$y\\totals.zip; done\n",
    "\n",
    "for ((y=0; y<=1; y+=1)); do wget ftp://ftp.census.gov/Econ2001_And_Earlier/CBP_CSV/zbp0$y\\totals.zip; done\n",
    "\n",
    "for ((y=2; y<=9; y+=1)); do wget ftp://ftp.census.gov/econ200$y\\/CBP_CSV/zbp0$y\\totals.zip; done\n",
    "\n",
    "for ((y=10; y<=15; y+=1)); do wget ftp://ftp.census.gov/econ20$y\\/CBP_CSV/zbp$y\\totals.zip; done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the zip file list of nyc department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "url = \"https://nycdatastables.s3.amazonaws.com/2013-08-19T18:18:28.877Z/nyc-zip-code-tabulation-areas-polygons.geojson\"\n",
    "request = urllib2.urlopen(url)\n",
    "nyc = json.load(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# store the nyc_zip\n",
    "nyc_zip = []\n",
    "for department in nyc['features']:\n",
    "    nyc_zip.append(str(department['properties'][\"postalCode\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.getcwd()+'/data'\n",
    "path\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import zipfile #i am not giving it a name cause i intend to use it only once\n",
    "tr0 = range(1994,2014)\n",
    "tr1 = range(1998,2003)\n",
    "ffname = \"zbp{0}totals.zip\"\n",
    "biz_zip = set()\n",
    "for i in tr0:\n",
    "    if i in tr1:\n",
    "        st = str(i)[2:]\n",
    "        fname = ffname.format(st)\n",
    "        zf = zipfile.ZipFile(fname)\n",
    "        df = pd.read_csv(zf.open(fname.replace('.zip','.txt')),dtype={'ZIP':str})\n",
    "        df.columns=[u'zip', u'name', u'empflag', u'emp', u'qp1', u'ap', u'est']\n",
    "    else:\n",
    "        st = str(i)[2:]\n",
    "        fname = ffname.format(st)\n",
    "        zf = zipfile.ZipFile(fname)\n",
    "        df = pd.read_csv(zf.open(fname.replace('.zip','.txt')),dtype={'zip':str})\n",
    "    new_zip = set(df.zip).intersection(set(nyc_zip))\n",
    "    biz_zip = biz_zip.union(new_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biz_zip = sorted(biz_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biz_data_est = pd.DataFrame('NA',index=biz_zip,columns=tr0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in tr0:\n",
    "    if i in tr1:\n",
    "        st = str(i)[2:]\n",
    "        fname = ffname.format(st)\n",
    "        zf = zipfile.ZipFile(fname)\n",
    "        df = pd.read_csv(zf.open(fname.replace('.zip','.txt')),dtype={'ZIP':str})\n",
    "        df.columns=[u'zip', u'name', u'empflag', u'emp', u'qp1', u'ap', u'est']\n",
    "    else:\n",
    "        st = str(i)[2:]\n",
    "        fname = ffname.format(st)\n",
    "        zf = zipfile.ZipFile(fname)\n",
    "        df = pd.read_csv(zf.open(fname.replace('.zip','.txt')),dtype={'zip':str})\n",
    "    for j in biz_zip:\n",
    "        if j in list(set(df.zip)):\n",
    "            biz = df[df.zip==j]\n",
    "            biz_data_est.loc[j][i]=int(biz.est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biz_data_est.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you may need to clean your data: for some NYC zip codes there may be no info\n",
    "    \n",
    "sanity check: you should have 20 (Ntimestamps) datapoints per time series and about 250 zipcodes (Nzipcodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "IMPORTANT: we talked about the importance of \"whitening\" your data: dividing each feature by its standard deviation. \n",
    "Whitenings decorrelates the data: it makes the features independent so that the data covariance matrix is the identity matrix.\n",
    "Whitening your data in time series analysis is in most cases **wrong**: you are modifying your time behaviour. This is because of the strong correlation between features (two consecutive time stamps for the same observation, the same zip code here, are strongly correlated). Here instead you want to standardize your time series: subtract the mean and divide each time series (separately) by its standard deviation. As a sanity check (if you use skitlearn Kmeans or skitlearns kmeans2): you want your data array to be shaped Nzipcodes x Ntimestamps\n",
    "\n",
    "mydata.shape should be (Nzipcodes, Ntimestamps)\n",
    "\n",
    "mydata[i].std() shoould be 1 for all i in range(len(Nzipcodes))\n",
    "\n",
    "mydata[i].mean() should be ~0 for all i in range(len(Nzipcodes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "TASKS:\n",
    "    \n",
    "    1. get and prep your data.\n",
    "    2. cluster the time series with K-means in **a few** clusters (as discussed there is no real good, sound way to decide what a good number is here. try a few options, keeping in mind a few is more than a couple, but i recommand you stay within the single digit numbers)\n",
    "    3. plot the cluster centers (if you used K means those are the means of the clusters). you can plot for example the cluster centers overlayed on each time series (using the alpha channel to control the opacity in the plot may be helpful here).\n",
    "    4. Use another clustering algorithm (of your choice)\n",
    "    5. overlay your data on a NYC map: you can use shapefiles for the zip codes and different colors for different clusters\n",
    "    6. Compare the results of the 2 algorithms\n",
    "    7. attempt an interpretation. this is dangerous ground: clustering is an exploratory tool so you do not want to jump to conclusions because you see some clusters! but seeing structure in your data can inform your next moves as an investigator. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
